{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.4"
    },
    "colab": {
      "name": "tp_segm.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "17da7f75"
      },
      "source": [
        "Teaching assistant:\n",
        "\n",
        "thomas.langrognet@mines-paristech.fr\n",
        "\n",
        "# Load the dependencies\n",
        "\n"
      ],
      "id": "17da7f75"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "38cc29a8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92d27d82-e645-44f1-9602-2c7c6a75c09a"
      },
      "source": [
        "import os\n",
        "import json\n",
        "from datetime import datetime\n",
        "import tensorflow as tf\n",
        "import tensorflow.keras as keras\n",
        "from tensorflow.python.keras import backend as K\n",
        "import imageio\n",
        "import numpy as np\n",
        "from scipy import ndimage\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "id": "38cc29a8",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/gdrive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5F1XWeSkLxcz"
      },
      "source": [
        "## Data\n",
        "\n",
        "Create a directory named *data* in your google drive. This directory will be the workspace of the TP. Once, created, copy/paste the dataset folder *tissue* in *data*. Do not modify the folder *tissue*. \n",
        "\n",
        "\n",
        "Set the correct path in the cell below. Then run this cell set the script at the *data* level."
      ],
      "id": "5F1XWeSkLxcz"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBXjAU-KL1_3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e4a2b6cf-f6fd-4b20-8237-3f9db4c9d18d"
      },
      "source": [
        "%cd 'gdrive/MyDrive/data'"
      ],
      "id": "LBXjAU-KL1_3",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/MyDrive/data\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fc28ac0c"
      },
      "source": [
        "# DataGenerator fetching the data\n",
        "\n",
        "Implement the functions in charge of selecting patches of images within the customised keras DataGenerator class.  \n",
        "The function *get_random_patch_coord* randomly selects the coordinates of an image's patch. A *patch_coord* points to the lower left corner of the corresponding patch. Thus the coordinates [a,b] gives for a patch of size [c, d] the image's patch *image*[a:a+c,b:b+d].  \n",
        "The function *choose_patch_coord* calls *get_random_patch_coord* and should return the coordinates of a patch with at most 70% of background labels (pixel value of 0 in label). If it cannot be achieved after 10 tryouts, the function should return the coordinates of the patch with the lowest background labels found.  "
      ],
      "id": "fc28ac0c"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1f786f4a"
      },
      "source": [
        "class DataGeneratorTissue(keras.utils.Sequence):\n",
        "    \n",
        "    def __init__(self, path, prefix, batch_size, \n",
        "                 patch_size, nb_channels_in=3, nb_channels_out=1,\n",
        "                 geometric_augmentations=[], augmentation_ratio=None):\n",
        "        \n",
        "        self.path = path\n",
        "        self.prefix = prefix\n",
        "        self.get_data_dict()\n",
        "        self.batch_size = batch_size\n",
        "        self.patch_size = patch_size\n",
        "        self.nb_channels_in = nb_channels_in\n",
        "        self.nb_channels_out = nb_channels_out\n",
        "        self.geometric_augmentations = []\n",
        "        self.augmentation_ratio = augmentation_ratio\n",
        "        \n",
        "        self.on_epoch_end()\n",
        "        \n",
        "    def __len__(self):\n",
        "        return int(np.floor(len(self.data) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, batch_idx):\n",
        "        batch_data_idxs = self.data_idxs[batch_idx*self.batch_size:(batch_idx+1)*self.batch_size]\n",
        "        x, y = self.fetch_data(batch_data_idxs)\n",
        "        return x, y\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        self.data_idxs = np.arange(len(self.data))\n",
        "        np.random.shuffle(self.data_idxs)\n",
        "    \n",
        "    def get_data_dict(self):\n",
        "        self.data = {}\n",
        "        for data_idx, image_name in enumerate(os.listdir(os.path.join(*[self.path, self.prefix, \"jpg\"]))):\n",
        "            self.data[data_idx] = image_name\n",
        "    \n",
        "    def get_random_patch_coord(self, image_size):\n",
        "      # we a tuple of random coordinates (x,y)\n",
        "      # (x,y) belong to [0, image_size0 - patch_size0; 0, image_size1 - patch_size1]\n",
        "      random_x = np.random.randint(low = 0, high=image_size[0] - self.patch_size[0])\n",
        "      random_y = np.random.randint(low = 0, high=image_size[1] - self.patch_size[1])\n",
        "      return (random_x, random_y)\n",
        "    \n",
        "    def choose_patch_coord(self, image_shape, label):\n",
        "        # HINTS\n",
        "        patch_coord_found = False\n",
        "        threshold = 70\n",
        "        itr = 0\n",
        "        best_patch_coord = None\n",
        "        lowest_bg_per = np.inf\n",
        "        \n",
        "        while (patch_coord_found == False) and (itr < 10):\n",
        "            patch_coord = self.get_random_patch_coord(image_shape)\n",
        "            # print(\"Coords:\", patch_coord)\n",
        "            positives = np.count_nonzero(label[patch_coord[0] : patch_coord[0] + self.patch_size[0], patch_coord[0] : patch_coord[1] + self.patch_size[1]])\n",
        "            percent_label_non_0 = positives / (patch_size[0] * patch_size[1])\n",
        "            # print(\"%non0: \", percent_label_non_0)\n",
        "\n",
        "            percent_label_0 = 1 - percent_label_non_0\n",
        "            # print(\"%0:\", percent_label_0)\n",
        "\n",
        "            if(percent_label_0 <= threshold / 100):\n",
        "              # print(\"found good\")\n",
        "              # we have less than 70% of background\n",
        "              return patch_coord\n",
        "            \n",
        "            \n",
        "            # we do not have less than 70% of background\n",
        "            # let's check the result\n",
        "            if percent_label_0 < lowest_bg_per:\n",
        "              # the new one is closest to 70% than the previous one\n",
        "              lowest_bg_per = percent_label_0\n",
        "              best_patch_coord = patch_coord\n",
        "            \n",
        "            itr+=1\n",
        "          \n",
        "        # print(\"did not: \", lowest_bg_per)\n",
        "\n",
        "        return best_patch_coord\n",
        "        \n",
        "    def fetch_data(self, batch_data_idxs):\n",
        "        x = np.empty([self.batch_size, *self.patch_size, self.nb_channels_in])\n",
        "        y = np.empty([self.batch_size, *self.patch_size, self.nb_channels_out])\n",
        "        \n",
        "        for idx, data_idx in enumerate(batch_data_idxs):\n",
        "            image_file_path = os.path.join(*[self.path, self.prefix, \"jpg\", self.data[data_idx]])\n",
        "            image = imageio.imread(image_file_path)\n",
        "            \n",
        "            label_file_path = os.path.join(*[self.path, self.prefix, \"lbl\", self.data[data_idx]])\n",
        "            label = imageio.imread(label_file_path)\n",
        "            \n",
        "            image = np.float32(image/255)\n",
        "            label = np.expand_dims(np.float32(label/255), axis=-1)\n",
        "            \n",
        "            patch_coord = self.choose_patch_coord(list(image.shape[:2]), label)\n",
        "            \n",
        "            image_patch = image[patch_coord[0]:patch_coord[0]+self.patch_size[0], \n",
        "                                patch_coord[1]:patch_coord[1]+self.patch_size[1],:]\n",
        "            label_patch = label[patch_coord[0]:patch_coord[0]+self.patch_size[0], \n",
        "                                patch_coord[1]:patch_coord[1]+self.patch_size[1],:]\n",
        "            \n",
        "            if len(self.geometric_augmentations) != 0:\n",
        "                if np.random.binomial(1, self.augmentation_ratio) == 1:\n",
        "                    augm_idx = random.randint(0,len(self.geometric_augmentations)-1)\n",
        "                    image_patch, label_patch = self.geometric_augmentations[augm_idx](image_patch, label_patch)\n",
        "                              \n",
        "            x[idx:idx+1,...] = image_patch\n",
        "            y[idx:idx+1,...] = label_patch\n",
        "            \n",
        "        return x, y"
      ],
      "id": "1f786f4a",
      "execution_count": 52,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "973e10af"
      },
      "source": [
        "# UNet model builder\n",
        "\n",
        "Implement the encoder and decoder parts of the UNet model with skip connections in the *build_unet_model* function using only *conv_block*, *up_sampler* and *keras.layers.Concatenate()* functions."
      ],
      "id": "973e10af"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fbea0d76"
      },
      "source": [
        "def conv_block(filters, strides, last_activation=None):\n",
        "    if last_activation == None:\n",
        "        conv_block = keras.Sequential([keras.layers.Conv2D(filters=filters, kernel_size=3, \n",
        "                                                           strides=1, padding=\"same\", \n",
        "                                                           kernel_initializer = \"he_normal\"),\n",
        "                                       keras.layers.BatchNormalization(),\n",
        "                                       keras.layers.LeakyReLU(), \n",
        "                                       keras.layers.Conv2D(filters=filters, kernel_size=3, \n",
        "                                                           strides=strides, padding=\"same\", \n",
        "                                                           kernel_initializer = \"he_normal\"), \n",
        "                                       keras.layers.BatchNormalization(), \n",
        "                                       keras.layers.LeakyReLU()])\n",
        "    else:\n",
        "        conv_block = keras.Sequential([keras.layers.Conv2D(filters=filters, kernel_size=3, \n",
        "                                                           strides=strides, padding=\"same\", \n",
        "                                                           kernel_initializer = \"he_normal\"),\n",
        "                                       keras.layers.BatchNormalization(),\n",
        "                                       keras.layers.Activation(last_activation)])\n",
        "    return conv_block\n",
        "\n",
        "def up_sampler(filters):\n",
        "    up_sampler = keras.Sequential([keras.layers.Conv2DTranspose(filters=filters, kernel_size=2, \n",
        "                                                                strides=2, padding=\"valid\", \n",
        "                                                                kernel_initializer = \"he_normal\"), \n",
        "                                   keras.layers.BatchNormalization(), \n",
        "                                   keras.layers.LeakyReLU()])\n",
        "    return up_sampler\n",
        "    \n",
        "def build_unet_model(nb_channels_in, nb_channels_out, \n",
        "                     unet_filters, last_activation, \n",
        "                     image_size=[None, None]):\n",
        "    # nb_channels_in: number of channels in the first layer\n",
        "    # nb_channels_out: number of channels in the output layer\n",
        "    # unet_filters: list of filters in each block\n",
        "    # last_activation: the function to be used as last activation\n",
        "    # image_size: the size of input image\n",
        "    inputs = keras.Input([*image_size, nb_channels_in])\n",
        "    \n",
        "    x = inputs\n",
        "    skip = []\n",
        "    first = True\n",
        "    for i in range(len(unet_filters)):\n",
        "        # the number of filters in this layer\n",
        "        filters = unet_filters[i]\n",
        "\n",
        "        new_block = None\n",
        "\n",
        "        if first:\n",
        "          # we do not change the size for now\n",
        "          new_block = conv_block(filters, strides = 1)(x)\n",
        "          first = False\n",
        "        else:\n",
        "          # we want to divide by two the size\n",
        "          new_block = conv_block(filters, strides = 2)(x)\n",
        "        skip.append(new_block)\n",
        "        x = new_block\n",
        "    \n",
        "    # x now contains the last block (at the bottom of the U)\n",
        "    print('last block', x)\n",
        "\n",
        "    for i in reversed(range(len(unet_filters)-1)):\n",
        "        # the number of filters in this layer\n",
        "        filters = unet_filters[i]\n",
        "        print(\"actual filters:\" + str(filters))\n",
        "\n",
        "        # we create the new layer one from the previous layer\n",
        "        x = up_sampler(filters)(x)\n",
        "        # x = conv_block(filters, strides = 1)(x)\n",
        "        # then, we concatenate the skip layer\n",
        "        x = keras.layers.Concatenate() ([skip[i], x])\n",
        "        x = conv_block(filters = filters, strides = 1)(x)\n",
        "        \n",
        "    \n",
        "    outputs = conv_block(nb_channels_out, 1, last_activation)(x)\n",
        "\n",
        "    unet_model = keras.Model(inputs, outputs)\n",
        "    return unet_model"
      ],
      "id": "fbea0d76",
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dee0ea60"
      },
      "source": [
        "# Segmentation loss\n",
        "\n",
        "Implement the computation of the cardinal of the intersection and the union between *y_true* and *y_pred*, stored in the variables *intersection* and *union* for the jaccard index-based loss. The function *K.sum()* should be sufficient to do so."
      ],
      "id": "dee0ea60"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "10d6c8f7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2bf8385c-268b-4cd4-d04e-693c8c512c76"
      },
      "source": [
        "def jaccard_loss(y_true, y_pred, smooth=1.0):\n",
        "    y_true_f = K.flatten(y_true)\n",
        "    y_pred_f = K.flatten(y_pred)\n",
        "\n",
        "    intersection = K.sum(y_true_f * y_pred_f)\n",
        "    union = K.sum(y_true_f) + K.sum(y_pred_f) - intersection\n",
        "    return 1 - (intersection + smooth) / (union + smooth)\n",
        "\n",
        "jaccard_loss(tf.constant([[0, 1],\n",
        "                        [1, 0]], dtype=tf.float32),\n",
        "             tf.constant([[1, 1],\n",
        "                        [1, 0]], dtype=tf.float32))"
      ],
      "id": "10d6c8f7",
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(), dtype=float32, numpy=0.25>"
            ]
          },
          "metadata": {},
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "b79b93cd"
      },
      "source": [
        "# Data augmentation\n",
        "\n",
        "Basic geometric data augmentation. Nothing to implement."
      ],
      "id": "b79b93cd"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bc15cdf5"
      },
      "source": [
        "def flip_aug(image, label):\n",
        "    flipped_image = np.flip(image, axis=1)\n",
        "    flipped_label = np.flip(label, axis=1)\n",
        "    return flipped_image, flipped_label\n",
        "\n",
        "def rot_aug(image, label):\n",
        "    image_rotation = ndimage.rotate(image, angle=random.randint(low=-20, high=20))\n",
        "    label_rotation = ndimage.rotate(label, angle=random.randint(low=-20, high=20))\n",
        "    return image_rotation, label_rotation"
      ],
      "id": "bc15cdf5",
      "execution_count": 55,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4ac71ebf"
      },
      "source": [
        "# Model's training\n",
        "\n",
        "Launch the training of a UNet with the given hyperparameters on the gpu \"gpu:/0\" (the first gpu visible by cuda).  \n",
        "A directory named \"models\", where are located the models' directories storing the data of the differents models trained, should be created. .  \n",
        "In a model's directory, named according the model's id and the timestamp of its training (a security to avoid accidental overwriting), are stored the *model_parameters.json*, *best_model_weights.h5* and *log.csv* files.  \n",
        "Nothing to implement, just run for training."
      ],
      "id": "4ac71ebf"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dd27f3a7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "94723ce3-c59a-465b-eb8b-a9365f64e0ac"
      },
      "source": [
        "path = \"./tissue\"\n",
        "\n",
        "models_dir = \"models\"\n",
        "if os.path.exists(models_dir) == False:\n",
        "    os.mkdir(models_dir)\n",
        "\n",
        "model_id = 1\n",
        "\n",
        "dt = datetime.now()\n",
        "timestamp = str(dt.hour) + ':' + str(dt.minute) + ':' + str(dt.second) + '-' + str(dt.day) + ':' + str(dt.month) + ':' + str(dt.year)\n",
        "model_name = \"modelID=\" + str(model_id) +  \"_timestamp=\" + timestamp\n",
        "\n",
        "model_dir = os.path.join(models_dir, model_name)\n",
        "if os.path.exists(model_dir) == False:\n",
        "    os.mkdir(model_dir)\n",
        "\n",
        "nb_channels_in = 3\n",
        "nb_channels_out = 1\n",
        "last_activation = \"sigmoid\"\n",
        "unet_filters = [8, 16, 32, 64]\n",
        "patch_size = [128, 128]\n",
        "batch_size = 5\n",
        "lr = 0.0001\n",
        "nb_epochs = 200\n",
        "\n",
        "model_parameters = {\"nb_channels_in\": nb_channels_in,\n",
        "                    \"nb_channels_out\": nb_channels_out,\n",
        "                    \"last_activation\": last_activation,\n",
        "                    \"unet_filters\": unet_filters,\n",
        "                    \"patch_size\": patch_size,\n",
        "                    \"batch_size\": batch_size,\n",
        "                    \"lr\": lr,\n",
        "                    \"nb_epochs\": nb_epochs}\n",
        "\n",
        "json.dump(model_parameters, open(os.path.join(model_dir, \"model_parameters.json\"), \"w\"))\n",
        "\n",
        "model = build_unet_model(3, 1, unet_filters, \"sigmoid\", image_size = patch_size)\n",
        "model.summary()\n",
        "\n",
        "train_datagen = DataGeneratorTissue(path, \"train\", batch_size, \n",
        "                                    patch_size, 3, 1,\n",
        "                                    geometric_augmentations=[flip_aug, rot_aug], augmentation_ratio=0.2)\n",
        "\n",
        "val_datagen = DataGeneratorTissue(path, \"val\", batch_size, \n",
        "                                  patch_size, 3, 1)\n",
        "\n",
        "opt = keras.optimizers.Adam(lr)\n",
        "model.compile(optimizer=opt, loss=jaccard_loss)\n",
        "\n",
        "model_log_file_path = os.path.join(model_dir, \"log.csv\")\n",
        "best_model_weights_file_path = os.path.join(model_dir, \"best_model_weights.h5\")\n",
        "\n",
        "callbacks = [\n",
        "    keras.callbacks.CSVLogger(model_log_file_path),\n",
        "    keras.callbacks.ModelCheckpoint(best_model_weights_file_path, \n",
        "                                    save_best_only=True, save_weights_only=True)]\n"
      ],
      "id": "dd27f3a7",
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "last block KerasTensor(type_spec=TensorSpec(shape=(None, 16, 16, 64), dtype=tf.float32, name=None), name='sequential_91/leaky_re_lu_143/LeakyRelu:0', description=\"created by layer 'sequential_91'\")\n",
            "actual filters:32\n",
            "actual filters:16\n",
            "actual filters:8\n",
            "Model: \"model_8\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_9 (InputLayer)            [(None, 128, 128, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "sequential_88 (Sequential)      (None, 128, 128, 8)  872         input_9[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "sequential_89 (Sequential)      (None, 64, 64, 16)   3616        sequential_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "sequential_90 (Sequential)      (None, 32, 32, 32)   14144       sequential_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "sequential_91 (Sequential)      (None, 16, 16, 64)   55936       sequential_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "sequential_92 (Sequential)      (None, 32, 32, 32)   8352        sequential_91[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_24 (Concatenate)    (None, 32, 32, 64)   0           sequential_90[0][0]              \n",
            "                                                                 sequential_92[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "sequential_93 (Sequential)      (None, 32, 32, 32)   27968       concatenate_24[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "sequential_94 (Sequential)      (None, 64, 64, 16)   2128        sequential_93[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_25 (Concatenate)    (None, 64, 64, 32)   0           sequential_89[0][0]              \n",
            "                                                                 sequential_94[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "sequential_95 (Sequential)      (None, 64, 64, 16)   7072        concatenate_25[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "sequential_96 (Sequential)      (None, 128, 128, 8)  552         sequential_95[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_26 (Concatenate)    (None, 128, 128, 16) 0           sequential_88[0][0]              \n",
            "                                                                 sequential_96[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "sequential_97 (Sequential)      (None, 128, 128, 8)  1808        concatenate_26[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "sequential_98 (Sequential)      (None, 128, 128, 1)  77          sequential_97[0][0]              \n",
            "==================================================================================================\n",
            "Total params: 122,525\n",
            "Trainable params: 121,707\n",
            "Non-trainable params: 818\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BDcgRxyrGiBY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aaf18cbe-389a-4ae3-b6a4-0bff816c2d5a"
      },
      "source": [
        "\n",
        "\n",
        "model.fit(train_datagen, \n",
        "          epochs=nb_epochs,\n",
        "          validation_data=val_datagen, \n",
        "          verbose=1,\n",
        "          callbacks=callbacks)"
      ],
      "id": "BDcgRxyrGiBY",
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/200\n",
            "20/20 [==============================] - 13s 595ms/step - loss: 0.8580 - val_loss: 0.8735\n",
            "Epoch 2/200\n",
            "20/20 [==============================] - 11s 571ms/step - loss: 0.7950 - val_loss: 0.8538\n",
            "Epoch 3/200\n",
            "20/20 [==============================] - 11s 559ms/step - loss: 0.7909 - val_loss: 0.8410\n",
            "Epoch 4/200\n",
            "20/20 [==============================] - 11s 555ms/step - loss: 0.7521 - val_loss: 0.8618\n",
            "Epoch 5/200\n",
            "20/20 [==============================] - 12s 586ms/step - loss: 0.7317 - val_loss: 0.8422\n",
            "Epoch 6/200\n",
            "20/20 [==============================] - 12s 600ms/step - loss: 0.7375 - val_loss: 0.8400\n",
            "Epoch 7/200\n",
            "20/20 [==============================] - 12s 578ms/step - loss: 0.7200 - val_loss: 0.7812\n",
            "Epoch 8/200\n",
            "20/20 [==============================] - 11s 567ms/step - loss: 0.6983 - val_loss: 0.7769\n",
            "Epoch 9/200\n",
            "20/20 [==============================] - 11s 554ms/step - loss: 0.7096 - val_loss: 0.7985\n",
            "Epoch 10/200\n",
            "20/20 [==============================] - 11s 562ms/step - loss: 0.7224 - val_loss: 0.7848\n",
            "Epoch 11/200\n",
            "20/20 [==============================] - 11s 564ms/step - loss: 0.7011 - val_loss: 0.8104\n",
            "Epoch 12/200\n",
            "20/20 [==============================] - 11s 555ms/step - loss: 0.6981 - val_loss: 0.7697\n",
            "Epoch 13/200\n",
            "20/20 [==============================] - 11s 565ms/step - loss: 0.7375 - val_loss: 0.7479\n",
            "Epoch 14/200\n",
            "20/20 [==============================] - 11s 558ms/step - loss: 0.7048 - val_loss: 0.7548\n",
            "Epoch 15/200\n",
            "20/20 [==============================] - 11s 551ms/step - loss: 0.7099 - val_loss: 0.7138\n",
            "Epoch 16/200\n",
            "20/20 [==============================] - 11s 556ms/step - loss: 0.6885 - val_loss: 0.7316\n",
            "Epoch 17/200\n",
            "20/20 [==============================] - 11s 551ms/step - loss: 0.6928 - val_loss: 0.6779\n",
            "Epoch 18/200\n",
            "20/20 [==============================] - 11s 553ms/step - loss: 0.6862 - val_loss: 0.7051\n",
            "Epoch 19/200\n",
            "20/20 [==============================] - 11s 551ms/step - loss: 0.6852 - val_loss: 0.7183\n",
            "Epoch 20/200\n",
            "20/20 [==============================] - 11s 556ms/step - loss: 0.7121 - val_loss: 0.7096\n",
            "Epoch 21/200\n",
            "20/20 [==============================] - 11s 553ms/step - loss: 0.6872 - val_loss: 0.6739\n",
            "Epoch 22/200\n",
            "20/20 [==============================] - 11s 556ms/step - loss: 0.7101 - val_loss: 0.7168\n",
            "Epoch 23/200\n",
            "20/20 [==============================] - 11s 558ms/step - loss: 0.7024 - val_loss: 0.7415\n",
            "Epoch 24/200\n",
            "20/20 [==============================] - 11s 559ms/step - loss: 0.6781 - val_loss: 0.7007\n",
            "Epoch 25/200\n",
            "20/20 [==============================] - 11s 561ms/step - loss: 0.6819 - val_loss: 0.6668\n",
            "Epoch 26/200\n",
            "20/20 [==============================] - 11s 551ms/step - loss: 0.6771 - val_loss: 0.6666\n",
            "Epoch 27/200\n",
            "20/20 [==============================] - 11s 558ms/step - loss: 0.7140 - val_loss: 0.6981\n",
            "Epoch 28/200\n",
            "20/20 [==============================] - 11s 546ms/step - loss: 0.6854 - val_loss: 0.7082\n",
            "Epoch 29/200\n",
            "20/20 [==============================] - 11s 549ms/step - loss: 0.6943 - val_loss: 0.6999\n",
            "Epoch 30/200\n",
            "20/20 [==============================] - 11s 549ms/step - loss: 0.6984 - val_loss: 0.7089\n",
            "Epoch 31/200\n",
            "20/20 [==============================] - 11s 548ms/step - loss: 0.6859 - val_loss: 0.6948\n",
            "Epoch 32/200\n",
            "20/20 [==============================] - 11s 544ms/step - loss: 0.6631 - val_loss: 0.7392\n",
            "Epoch 33/200\n",
            "20/20 [==============================] - 11s 552ms/step - loss: 0.6931 - val_loss: 0.7040\n",
            "Epoch 34/200\n",
            "20/20 [==============================] - 11s 553ms/step - loss: 0.6960 - val_loss: 0.7104\n",
            "Epoch 35/200\n",
            "20/20 [==============================] - 11s 547ms/step - loss: 0.6923 - val_loss: 0.7026\n",
            "Epoch 36/200\n",
            "20/20 [==============================] - 11s 548ms/step - loss: 0.6833 - val_loss: 0.6646\n",
            "Epoch 37/200\n",
            "20/20 [==============================] - 11s 551ms/step - loss: 0.6895 - val_loss: 0.6545\n",
            "Epoch 38/200\n",
            "20/20 [==============================] - 11s 547ms/step - loss: 0.6690 - val_loss: 0.7043\n",
            "Epoch 39/200\n",
            "20/20 [==============================] - 11s 554ms/step - loss: 0.7056 - val_loss: 0.7192\n",
            "Epoch 40/200\n",
            "20/20 [==============================] - 11s 551ms/step - loss: 0.7063 - val_loss: 0.7227\n",
            "Epoch 41/200\n",
            "20/20 [==============================] - 11s 547ms/step - loss: 0.7061 - val_loss: 0.6529\n",
            "Epoch 42/200\n",
            "20/20 [==============================] - 11s 551ms/step - loss: 0.6689 - val_loss: 0.7154\n",
            "Epoch 43/200\n",
            "20/20 [==============================] - 11s 551ms/step - loss: 0.7219 - val_loss: 0.6817\n",
            "Epoch 44/200\n",
            "20/20 [==============================] - 11s 550ms/step - loss: 0.6823 - val_loss: 0.7019\n",
            "Epoch 45/200\n",
            "20/20 [==============================] - 11s 554ms/step - loss: 0.6843 - val_loss: 0.6761\n",
            "Epoch 46/200\n",
            "20/20 [==============================] - 11s 556ms/step - loss: 0.6823 - val_loss: 0.7477\n",
            "Epoch 47/200\n",
            "20/20 [==============================] - 11s 550ms/step - loss: 0.6787 - val_loss: 0.6560\n",
            "Epoch 48/200\n",
            "20/20 [==============================] - 11s 548ms/step - loss: 0.6602 - val_loss: 0.6828\n",
            "Epoch 49/200\n",
            "20/20 [==============================] - 11s 558ms/step - loss: 0.7121 - val_loss: 0.7029\n",
            "Epoch 50/200\n",
            "20/20 [==============================] - 11s 554ms/step - loss: 0.6845 - val_loss: 0.6819\n",
            "Epoch 51/200\n",
            "20/20 [==============================] - 11s 559ms/step - loss: 0.6974 - val_loss: 0.6489\n",
            "Epoch 52/200\n",
            "20/20 [==============================] - 11s 556ms/step - loss: 0.6669 - val_loss: 0.6884\n",
            "Epoch 53/200\n",
            "20/20 [==============================] - 11s 556ms/step - loss: 0.7038 - val_loss: 0.6778\n",
            "Epoch 54/200\n",
            "20/20 [==============================] - 11s 551ms/step - loss: 0.6447 - val_loss: 0.6826\n",
            "Epoch 55/200\n",
            "20/20 [==============================] - 11s 554ms/step - loss: 0.6760 - val_loss: 0.7172\n",
            "Epoch 56/200\n",
            "20/20 [==============================] - 11s 560ms/step - loss: 0.6609 - val_loss: 0.6830\n",
            "Epoch 57/200\n",
            "20/20 [==============================] - 11s 556ms/step - loss: 0.6733 - val_loss: 0.7003\n",
            "Epoch 58/200\n",
            "20/20 [==============================] - 11s 550ms/step - loss: 0.6962 - val_loss: 0.6868\n",
            "Epoch 59/200\n",
            "20/20 [==============================] - 11s 549ms/step - loss: 0.6641 - val_loss: 0.6940\n",
            "Epoch 60/200\n",
            "20/20 [==============================] - 11s 551ms/step - loss: 0.6618 - val_loss: 0.7142\n",
            "Epoch 61/200\n",
            "20/20 [==============================] - 11s 561ms/step - loss: 0.6801 - val_loss: 0.7207\n",
            "Epoch 62/200\n",
            "20/20 [==============================] - 11s 568ms/step - loss: 0.6680 - val_loss: 0.6632\n",
            "Epoch 63/200\n",
            "20/20 [==============================] - 11s 567ms/step - loss: 0.6958 - val_loss: 0.6902\n",
            "Epoch 64/200\n",
            "20/20 [==============================] - 12s 589ms/step - loss: 0.6491 - val_loss: 0.6685\n",
            "Epoch 65/200\n",
            "20/20 [==============================] - 12s 594ms/step - loss: 0.6523 - val_loss: 0.6454\n",
            "Epoch 66/200\n",
            "20/20 [==============================] - 12s 589ms/step - loss: 0.6564 - val_loss: 0.6605\n",
            "Epoch 67/200\n",
            "20/20 [==============================] - 12s 584ms/step - loss: 0.6857 - val_loss: 0.6983\n",
            "Epoch 68/200\n",
            "20/20 [==============================] - 11s 567ms/step - loss: 0.6438 - val_loss: 0.6621\n",
            "Epoch 69/200\n",
            "20/20 [==============================] - 11s 574ms/step - loss: 0.6418 - val_loss: 0.6948\n",
            "Epoch 70/200\n",
            "20/20 [==============================] - 12s 577ms/step - loss: 0.6885 - val_loss: 0.6862\n",
            "Epoch 71/200\n",
            "20/20 [==============================] - 11s 575ms/step - loss: 0.6828 - val_loss: 0.6959\n",
            "Epoch 72/200\n",
            "20/20 [==============================] - 11s 570ms/step - loss: 0.6816 - val_loss: 0.6633\n",
            "Epoch 73/200\n",
            "20/20 [==============================] - 12s 582ms/step - loss: 0.6571 - val_loss: 0.6713\n",
            "Epoch 74/200\n",
            "20/20 [==============================] - 11s 574ms/step - loss: 0.6870 - val_loss: 0.6571\n",
            "Epoch 75/200\n",
            "20/20 [==============================] - 11s 573ms/step - loss: 0.6606 - val_loss: 0.7192\n",
            "Epoch 76/200\n",
            "20/20 [==============================] - 11s 571ms/step - loss: 0.6524 - val_loss: 0.7202\n",
            "Epoch 77/200\n",
            "20/20 [==============================] - 12s 578ms/step - loss: 0.6992 - val_loss: 0.6492\n",
            "Epoch 78/200\n",
            "20/20 [==============================] - 12s 583ms/step - loss: 0.6796 - val_loss: 0.7137\n",
            "Epoch 79/200\n",
            "20/20 [==============================] - 11s 574ms/step - loss: 0.6679 - val_loss: 0.6558\n",
            "Epoch 80/200\n",
            "20/20 [==============================] - 11s 572ms/step - loss: 0.6648 - val_loss: 0.6370\n",
            "Epoch 81/200\n",
            "20/20 [==============================] - 12s 576ms/step - loss: 0.6826 - val_loss: 0.6957\n",
            "Epoch 82/200\n",
            "20/20 [==============================] - 11s 573ms/step - loss: 0.6488 - val_loss: 0.6465\n",
            "Epoch 83/200\n",
            "20/20 [==============================] - 12s 586ms/step - loss: 0.6449 - val_loss: 0.6624\n",
            "Epoch 84/200\n",
            "20/20 [==============================] - 12s 576ms/step - loss: 0.6847 - val_loss: 0.6877\n",
            "Epoch 85/200\n",
            "20/20 [==============================] - 12s 578ms/step - loss: 0.6565 - val_loss: 0.6795\n",
            "Epoch 86/200\n",
            "20/20 [==============================] - 11s 571ms/step - loss: 0.6571 - val_loss: 0.6485\n",
            "Epoch 87/200\n",
            "20/20 [==============================] - 12s 578ms/step - loss: 0.6661 - val_loss: 0.7281\n",
            "Epoch 88/200\n",
            "20/20 [==============================] - 12s 581ms/step - loss: 0.6826 - val_loss: 0.6446\n",
            "Epoch 89/200\n",
            "20/20 [==============================] - 12s 583ms/step - loss: 0.6541 - val_loss: 0.7315\n",
            "Epoch 90/200\n",
            "20/20 [==============================] - 12s 583ms/step - loss: 0.6809 - val_loss: 0.6905\n",
            "Epoch 91/200\n",
            "20/20 [==============================] - 12s 588ms/step - loss: 0.6544 - val_loss: 0.6543\n",
            "Epoch 92/200\n",
            "20/20 [==============================] - 12s 581ms/step - loss: 0.6505 - val_loss: 0.7011\n",
            "Epoch 93/200\n",
            "20/20 [==============================] - 12s 578ms/step - loss: 0.6949 - val_loss: 0.6365\n",
            "Epoch 94/200\n",
            "20/20 [==============================] - 12s 583ms/step - loss: 0.6332 - val_loss: 0.6083\n",
            "Epoch 95/200\n",
            "20/20 [==============================] - 12s 579ms/step - loss: 0.6707 - val_loss: 0.7304\n",
            "Epoch 96/200\n",
            "20/20 [==============================] - 12s 576ms/step - loss: 0.6407 - val_loss: 0.6674\n",
            "Epoch 97/200\n",
            "20/20 [==============================] - 11s 572ms/step - loss: 0.6562 - val_loss: 0.6851\n",
            "Epoch 98/200\n",
            "20/20 [==============================] - 11s 575ms/step - loss: 0.6456 - val_loss: 0.6778\n",
            "Epoch 99/200\n",
            "20/20 [==============================] - 11s 575ms/step - loss: 0.6760 - val_loss: 0.6438\n",
            "Epoch 100/200\n",
            "20/20 [==============================] - 12s 578ms/step - loss: 0.6787 - val_loss: 0.6674\n",
            "Epoch 101/200\n",
            "20/20 [==============================] - 12s 580ms/step - loss: 0.6501 - val_loss: 0.6812\n",
            "Epoch 102/200\n",
            "20/20 [==============================] - 11s 573ms/step - loss: 0.6434 - val_loss: 0.6858\n",
            "Epoch 103/200\n",
            "20/20 [==============================] - 12s 576ms/step - loss: 0.6674 - val_loss: 0.6721\n",
            "Epoch 104/200\n",
            "20/20 [==============================] - 11s 570ms/step - loss: 0.6322 - val_loss: 0.6784\n",
            "Epoch 105/200\n",
            "20/20 [==============================] - 12s 579ms/step - loss: 0.6698 - val_loss: 0.6298\n",
            "Epoch 106/200\n",
            "20/20 [==============================] - 12s 577ms/step - loss: 0.6403 - val_loss: 0.6889\n",
            "Epoch 107/200\n",
            "20/20 [==============================] - 11s 566ms/step - loss: 0.6619 - val_loss: 0.7184\n",
            "Epoch 108/200\n",
            "20/20 [==============================] - 11s 571ms/step - loss: 0.6603 - val_loss: 0.6567\n",
            "Epoch 109/200\n",
            "20/20 [==============================] - 11s 572ms/step - loss: 0.6468 - val_loss: 0.6562\n",
            "Epoch 110/200\n",
            "20/20 [==============================] - 12s 576ms/step - loss: 0.6551 - val_loss: 0.6695\n",
            "Epoch 111/200\n",
            "20/20 [==============================] - 12s 577ms/step - loss: 0.6454 - val_loss: 0.6466\n",
            "Epoch 112/200\n",
            "20/20 [==============================] - 11s 573ms/step - loss: 0.6103 - val_loss: 0.6724\n",
            "Epoch 113/200\n",
            "20/20 [==============================] - 12s 575ms/step - loss: 0.6633 - val_loss: 0.6832\n",
            "Epoch 114/200\n",
            "20/20 [==============================] - 12s 577ms/step - loss: 0.6393 - val_loss: 0.6692\n",
            "Epoch 115/200\n",
            "20/20 [==============================] - 12s 575ms/step - loss: 0.6490 - val_loss: 0.6606\n",
            "Epoch 116/200\n",
            "20/20 [==============================] - 12s 579ms/step - loss: 0.6633 - val_loss: 0.6681\n",
            "Epoch 117/200\n",
            "20/20 [==============================] - 11s 571ms/step - loss: 0.6453 - val_loss: 0.6672\n",
            "Epoch 118/200\n",
            "20/20 [==============================] - 12s 575ms/step - loss: 0.6426 - val_loss: 0.6296\n",
            "Epoch 119/200\n",
            "20/20 [==============================] - 12s 576ms/step - loss: 0.6509 - val_loss: 0.6721\n",
            "Epoch 120/200\n",
            "20/20 [==============================] - 12s 575ms/step - loss: 0.6193 - val_loss: 0.6978\n",
            "Epoch 121/200\n",
            "20/20 [==============================] - 11s 570ms/step - loss: 0.6331 - val_loss: 0.6418\n",
            "Epoch 122/200\n",
            "20/20 [==============================] - 11s 575ms/step - loss: 0.6522 - val_loss: 0.6706\n",
            "Epoch 123/200\n",
            "20/20 [==============================] - 11s 572ms/step - loss: 0.6768 - val_loss: 0.6556\n",
            "Epoch 124/200\n",
            "20/20 [==============================] - 11s 575ms/step - loss: 0.6632 - val_loss: 0.6799\n",
            "Epoch 125/200\n",
            "20/20 [==============================] - 12s 577ms/step - loss: 0.6366 - val_loss: 0.6495\n",
            "Epoch 126/200\n",
            "20/20 [==============================] - 11s 571ms/step - loss: 0.6424 - val_loss: 0.6753\n",
            "Epoch 127/200\n",
            "20/20 [==============================] - 12s 577ms/step - loss: 0.6482 - val_loss: 0.6174\n",
            "Epoch 128/200\n",
            "20/20 [==============================] - 11s 572ms/step - loss: 0.6376 - val_loss: 0.6333\n",
            "Epoch 129/200\n",
            "20/20 [==============================] - 12s 575ms/step - loss: 0.6175 - val_loss: 0.6632\n",
            "Epoch 130/200\n",
            "20/20 [==============================] - 12s 583ms/step - loss: 0.6248 - val_loss: 0.6562\n",
            "Epoch 131/200\n",
            "20/20 [==============================] - 12s 580ms/step - loss: 0.6193 - val_loss: 0.6693\n",
            "Epoch 132/200\n",
            "20/20 [==============================] - 12s 580ms/step - loss: 0.6204 - val_loss: 0.6406\n",
            "Epoch 133/200\n",
            "20/20 [==============================] - 12s 580ms/step - loss: 0.6129 - val_loss: 0.6470\n",
            "Epoch 134/200\n",
            "20/20 [==============================] - 12s 577ms/step - loss: 0.6327 - val_loss: 0.6733\n",
            "Epoch 135/200\n",
            "20/20 [==============================] - 12s 579ms/step - loss: 0.6355 - val_loss: 0.6657\n",
            "Epoch 136/200\n",
            "20/20 [==============================] - 12s 580ms/step - loss: 0.6174 - val_loss: 0.6738\n",
            "Epoch 137/200\n",
            "20/20 [==============================] - 12s 580ms/step - loss: 0.6183 - val_loss: 0.6635\n",
            "Epoch 138/200\n",
            "20/20 [==============================] - 12s 578ms/step - loss: 0.6290 - val_loss: 0.6284\n",
            "Epoch 139/200\n",
            "20/20 [==============================] - 11s 570ms/step - loss: 0.6274 - val_loss: 0.6298\n",
            "Epoch 140/200\n",
            "20/20 [==============================] - 11s 563ms/step - loss: 0.6097 - val_loss: 0.7010\n",
            "Epoch 141/200\n",
            "20/20 [==============================] - 11s 559ms/step - loss: 0.6329 - val_loss: 0.6451\n",
            "Epoch 142/200\n",
            "20/20 [==============================] - 11s 556ms/step - loss: 0.6395 - val_loss: 0.6880\n",
            "Epoch 143/200\n",
            "20/20 [==============================] - 11s 552ms/step - loss: 0.6002 - val_loss: 0.6114\n",
            "Epoch 144/200\n",
            "20/20 [==============================] - 11s 564ms/step - loss: 0.6173 - val_loss: 0.6342\n",
            "Epoch 145/200\n",
            "20/20 [==============================] - 11s 560ms/step - loss: 0.6373 - val_loss: 0.6577\n",
            "Epoch 146/200\n",
            "20/20 [==============================] - 11s 564ms/step - loss: 0.6147 - val_loss: 0.7106\n",
            "Epoch 147/200\n",
            "20/20 [==============================] - 11s 565ms/step - loss: 0.6315 - val_loss: 0.6371\n",
            "Epoch 148/200\n",
            "20/20 [==============================] - 11s 560ms/step - loss: 0.6203 - val_loss: 0.6102\n",
            "Epoch 149/200\n",
            "20/20 [==============================] - 12s 578ms/step - loss: 0.6362 - val_loss: 0.6814\n",
            "Epoch 150/200\n",
            "20/20 [==============================] - 11s 555ms/step - loss: 0.6601 - val_loss: 0.5972\n",
            "Epoch 151/200\n",
            "20/20 [==============================] - 11s 561ms/step - loss: 0.6168 - val_loss: 0.6388\n",
            "Epoch 152/200\n",
            "20/20 [==============================] - 11s 572ms/step - loss: 0.6422 - val_loss: 0.6119\n",
            "Epoch 153/200\n",
            "20/20 [==============================] - 11s 555ms/step - loss: 0.6490 - val_loss: 0.6092\n",
            "Epoch 154/200\n",
            "20/20 [==============================] - 11s 557ms/step - loss: 0.6320 - val_loss: 0.6496\n",
            "Epoch 155/200\n",
            "20/20 [==============================] - 11s 553ms/step - loss: 0.6262 - val_loss: 0.6189\n",
            "Epoch 156/200\n",
            "20/20 [==============================] - 11s 564ms/step - loss: 0.6159 - val_loss: 0.5815\n",
            "Epoch 157/200\n",
            "20/20 [==============================] - 11s 559ms/step - loss: 0.6205 - val_loss: 0.6202\n",
            "Epoch 158/200\n",
            "20/20 [==============================] - 11s 561ms/step - loss: 0.6127 - val_loss: 0.6187\n",
            "Epoch 159/200\n",
            "20/20 [==============================] - 11s 558ms/step - loss: 0.6175 - val_loss: 0.6395\n",
            "Epoch 160/200\n",
            "20/20 [==============================] - 11s 558ms/step - loss: 0.6059 - val_loss: 0.6506\n",
            "Epoch 161/200\n",
            "20/20 [==============================] - 11s 555ms/step - loss: 0.6198 - val_loss: 0.6399\n",
            "Epoch 162/200\n",
            "20/20 [==============================] - 11s 563ms/step - loss: 0.5956 - val_loss: 0.6462\n",
            "Epoch 163/200\n",
            "20/20 [==============================] - 11s 561ms/step - loss: 0.5982 - val_loss: 0.6742\n",
            "Epoch 164/200\n",
            "20/20 [==============================] - 11s 556ms/step - loss: 0.6149 - val_loss: 0.7250\n",
            "Epoch 165/200\n",
            "20/20 [==============================] - 11s 560ms/step - loss: 0.6259 - val_loss: 0.6250\n",
            "Epoch 166/200\n",
            "20/20 [==============================] - 11s 561ms/step - loss: 0.6064 - val_loss: 0.6409\n",
            "Epoch 167/200\n",
            "20/20 [==============================] - 12s 576ms/step - loss: 0.5947 - val_loss: 0.6305\n",
            "Epoch 168/200\n",
            "20/20 [==============================] - 11s 571ms/step - loss: 0.6421 - val_loss: 0.6527\n",
            "Epoch 169/200\n",
            "20/20 [==============================] - 11s 567ms/step - loss: 0.6284 - val_loss: 0.6274\n",
            "Epoch 170/200\n",
            "20/20 [==============================] - 11s 554ms/step - loss: 0.6397 - val_loss: 0.6465\n",
            "Epoch 171/200\n",
            "20/20 [==============================] - 11s 550ms/step - loss: 0.6116 - val_loss: 0.5802\n",
            "Epoch 172/200\n",
            "20/20 [==============================] - 11s 550ms/step - loss: 0.6162 - val_loss: 0.6625\n",
            "Epoch 173/200\n",
            "20/20 [==============================] - 11s 557ms/step - loss: 0.5932 - val_loss: 0.6608\n",
            "Epoch 174/200\n",
            "20/20 [==============================] - 11s 547ms/step - loss: 0.6007 - val_loss: 0.6689\n",
            "Epoch 175/200\n",
            "20/20 [==============================] - 11s 558ms/step - loss: 0.6249 - val_loss: 0.6707\n",
            "Epoch 176/200\n",
            "20/20 [==============================] - 11s 558ms/step - loss: 0.6400 - val_loss: 0.6192\n",
            "Epoch 177/200\n",
            "20/20 [==============================] - 11s 555ms/step - loss: 0.6113 - val_loss: 0.5995\n",
            "Epoch 178/200\n",
            "20/20 [==============================] - 11s 552ms/step - loss: 0.6307 - val_loss: 0.6414\n",
            "Epoch 179/200\n",
            "20/20 [==============================] - 11s 551ms/step - loss: 0.6017 - val_loss: 0.6861\n",
            "Epoch 180/200\n",
            "20/20 [==============================] - 11s 551ms/step - loss: 0.6063 - val_loss: 0.5892\n",
            "Epoch 181/200\n",
            "20/20 [==============================] - 11s 560ms/step - loss: 0.6264 - val_loss: 0.6405\n",
            "Epoch 182/200\n",
            "20/20 [==============================] - 11s 554ms/step - loss: 0.6356 - val_loss: 0.6809\n",
            "Epoch 183/200\n",
            "20/20 [==============================] - 11s 570ms/step - loss: 0.6162 - val_loss: 0.5879\n",
            "Epoch 184/200\n",
            "20/20 [==============================] - 12s 580ms/step - loss: 0.6190 - val_loss: 0.5921\n",
            "Epoch 185/200\n",
            "20/20 [==============================] - 12s 588ms/step - loss: 0.6341 - val_loss: 0.5993\n",
            "Epoch 186/200\n",
            "20/20 [==============================] - 11s 567ms/step - loss: 0.6208 - val_loss: 0.6570\n",
            "Epoch 187/200\n",
            "20/20 [==============================] - 11s 562ms/step - loss: 0.6295 - val_loss: 0.6065\n",
            "Epoch 188/200\n",
            "20/20 [==============================] - 11s 571ms/step - loss: 0.6065 - val_loss: 0.6128\n",
            "Epoch 189/200\n",
            "20/20 [==============================] - 11s 561ms/step - loss: 0.5935 - val_loss: 0.5908\n",
            "Epoch 190/200\n",
            "20/20 [==============================] - 11s 569ms/step - loss: 0.5927 - val_loss: 0.5786\n",
            "Epoch 191/200\n",
            "20/20 [==============================] - 11s 573ms/step - loss: 0.5936 - val_loss: 0.6152\n",
            "Epoch 192/200\n",
            "20/20 [==============================] - 11s 571ms/step - loss: 0.6042 - val_loss: 0.6405\n",
            "Epoch 193/200\n",
            "20/20 [==============================] - 11s 570ms/step - loss: 0.6334 - val_loss: 0.6543\n",
            "Epoch 194/200\n",
            "20/20 [==============================] - 11s 570ms/step - loss: 0.6391 - val_loss: 0.6324\n",
            "Epoch 195/200\n",
            "20/20 [==============================] - 11s 565ms/step - loss: 0.5999 - val_loss: 0.6331\n",
            "Epoch 196/200\n",
            "20/20 [==============================] - 12s 578ms/step - loss: 0.5965 - val_loss: 0.6368\n",
            "Epoch 197/200\n",
            "20/20 [==============================] - 12s 581ms/step - loss: 0.6021 - val_loss: 0.5978\n",
            "Epoch 198/200\n",
            "20/20 [==============================] - 11s 565ms/step - loss: 0.6193 - val_loss: 0.6395\n",
            "Epoch 199/200\n",
            "20/20 [==============================] - 12s 580ms/step - loss: 0.6068 - val_loss: 0.6251\n",
            "Epoch 200/200\n",
            "20/20 [==============================] - 11s 576ms/step - loss: 0.5800 - val_loss: 0.6345\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f0c76ba82d0>"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0e66fbfb"
      },
      "source": [
        "# Model's training summary\n",
        "\n",
        "Plot the training and validation loss.  \n",
        "Nothing to implement."
      ],
      "id": "0e66fbfb"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "42069cb3",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 297
        },
        "outputId": "bf5434f6-c789-4c8a-bd16-c0d25b298484"
      },
      "source": [
        "df = pd.read_csv(model_log_file_path, sep=\",\")\n",
        "plt.plot(df[\"epoch\"], df[\"loss\"], \"r\", label=\"training loss\")\n",
        "plt.plot(df[\"epoch\"], df[\"val_loss\"], \"b\", label=\"validation loss\")\n",
        "plt.xlabel(\"epochs\")\n",
        "plt.ylabel(\"loss\")\n",
        "plt.legend()"
      ],
      "id": "42069cb3",
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.legend.Legend at 0x7f0c77bf4ad0>"
            ]
          },
          "metadata": {},
          "execution_count": 59
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6ca5c9b9"
      },
      "source": [
        "# Model's inference function (optional)\n",
        "\n",
        "*make_apply_unet_model* is the function to call to embeds a UNet model into a function in charge of the whole pipeline to get from an 8-bit image an 8-bit binary segmentation mask.  \n",
        "Implement the *apply_unet_model* function.\n",
        "Here the pipeline should include:  \n",
        "* a [0,1]-normalization  \n",
        "* a padding of the image (so that its dimension are 2^{unet_depth = len(unet_filters)-1} divisible)  \n",
        "* the application of the UNet model  \n",
        "* an unpadding of the UNet model's output (to retrieve the initial image dimensions)  \n",
        "* the conversion of the UNet model's output into a binary segmentation mask by taking the label with the highest probability for each pixel  \n",
        "\n",
        "The *pad_image* and *unpad_image* are already provided. The numpy function *np.where(condition, value if condition true, value if condition false)* should useful for an efficient conversion into a binary segmentation mask."
      ],
      "id": "6ca5c9b9"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "914b9cb9"
      },
      "source": [
        "def pad_image(image, unet_depth):\n",
        "    shape = image.shape[:2]  \n",
        "    if shape[0]%2**unet_depth != 0 or shape[1]%2**unet_depth != 0:\n",
        "        new_shape = [shape[0] + 2**unet_depth - shape[0]%2**unet_depth, \n",
        "                     shape[1] + 2**unet_depth - shape[1]%2**unet_depth]\n",
        "        new_image = np.empty([*new_shape, 3])\n",
        "        new_image[0:shape[0], 0:shape[1], :] = image[...]\n",
        "        \n",
        "        new_image[0:shape[0],shape[1]:new_shape[1],:] = image[:,shape[1]-(new_shape[1]-shape[1]):shape[1],:]\n",
        "        new_image[shape[0]:new_shape[0],0:shape[1],:] = image[shape[0]-(new_shape[0]-shape[0]):shape[0],:,:]\n",
        "        new_image[shape[0]:new_shape[0],shape[1]:new_shape[1],:] = image[shape[0]-(new_shape[0]-shape[0]):shape[0],shape[1]-(new_shape[1]-shape[1]):shape[1],:]\n",
        "        \n",
        "        return new_image\n",
        "    else:\n",
        "        return image\n",
        "    \n",
        "def unpad_image(image, old_shape):\n",
        "    im_shape = image.shape[:2]\n",
        "    if im_shape[0] == old_shape[0] and im_shape[1] == old_shape[1]:\n",
        "        return image\n",
        "    else:\n",
        "        new_image = image[0:old_shape[0], 0:old_shape[1], :]\n",
        "        return new_image\n",
        "    \n",
        "def apply_unet_model(unet_model, unet_depth, image):\n",
        "    #TO IMPLEMENT\n",
        "    \n",
        "    \n",
        "    \n",
        "    \n",
        "    return segm\n",
        "\n",
        "def make_apply_unet_model(unet_model, unet_depth):\n",
        "    return lambda image: apply_unet_model(unet_model, unet_depth, image)"
      ],
      "id": "914b9cb9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "abaacc51"
      },
      "source": [
        "# Model's application on test dataset\n",
        "\n",
        "Apply a UNet model on test dataset images.  \n",
        "The model is chosen with its id and a test image with its index.  \n",
        "Nothing to implement."
      ],
      "id": "abaacc51"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0c5eed57"
      },
      "source": [
        "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"-1\"\n",
        "\n",
        "model2load_id = 1\n",
        "\n",
        "for dir in os.listdir(\"models\"):\n",
        "    if len(dir.split(\"modelID\")) > 1:\n",
        "        id = int(dir.split(\"_\")[0].split(\"=\")[1])\n",
        "        if id == model2load_id:\n",
        "            model_dir = os.path.join(\"models\", dir)\n",
        "            break\n",
        "\n",
        "with open(os.path.join(model_dir, \"model_parameters.json\"), \"r\") as model_parameters_file:\n",
        "    model_parameters = json.load(model_parameters_file)\n",
        "\n",
        "weights_path = os.path.join(model_dir, \"best_model_weights.h5\")\n",
        "\n",
        "model2 = build_unet_model(model_parameters[\"nb_channels_in\"], \n",
        "                          model_parameters[\"nb_channels_out\"], \n",
        "                          model_parameters[\"unet_filters\"], \n",
        "                          model_parameters[\"last_activation\"])\n",
        "\n",
        "model2.load_weights(weights_path)\n",
        "    \n",
        "apply_model =  make_apply_unet_model(model2, len(model_parameters[\"unet_filters\"])-1) \n",
        "\n",
        "test_images_dir = os.path.join(path, \"test\")\n",
        "test_images_filenames = os.listdir(os.path.join(test_images_dir, \"jpg\"))\n",
        "\n",
        "test_image_idx = 8\n",
        "\n",
        "image = imageio.imread(os.path.join(*[test_images_dir, \"jpg\", test_images_filenames[test_image_idx]]))\n",
        "label = imageio.imread(os.path.join(*[test_images_dir, \"lbl\", test_images_filenames[test_image_idx]]))\n",
        "\n",
        "segm = apply_model(image)\n",
        "\n",
        "plt.figure(figsize=(8,8))\n",
        "plt.imshow(image)\n",
        "\n",
        "plt.figure(figsize=(8,8))\n",
        "plt.imshow(segm, cmap=\"gray\")\n",
        "\n",
        "plt.figure(figsize=(8,8))\n",
        "plt.imshow(label, cmap=\"gray\")"
      ],
      "id": "0c5eed57",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "64efbbd8"
      },
      "source": [
        ""
      ],
      "id": "64efbbd8",
      "execution_count": null,
      "outputs": []
    }
  ]
}